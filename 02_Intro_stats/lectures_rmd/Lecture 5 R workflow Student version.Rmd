---
title: "Lecture 5 Fitting Models in R: Introducing a data analysis workflow"
author: "you"
date: "19th August 2022"
output: html_document
---

## Understanding your data

In the last lecture, we discussed how a model can conceptually represent your experiment. In a statistical model, we clearly identify (1) the response variable, (2) the experimental factors and their potential interactions, and (3) other factors that may influence the response. In this workshop, we'll operationalise this and fit models using R.

When we fit a model in R, we obtain estimates of group means, treatment effects, and differences between effects. An estimate is always accompanied by a measure of uncertainty, called the standard error (SE). Estimates of treatment effects, together with their SEs allow us **infer** whether the true effects are different from zero. 

The R output from a model fit includes p-values to aid this inference. P-values are measures of evidence that the hypothesised effects are true effects.

Aside: P-values have come to play an oversized role in statistical inference, perhaps for the same reason that bibliometric data play an oversized role in assessing good scholarship. The p-value is a single number, and for that reason, it is vulnerable to unsophicated hackers who contort its meaning into a "make or break" statistic.  Researchers "learn" that p < 0.05 means they can publish their findings, whilst p > 0.05 means they should keep collecting data until p < 0.05 (or bury their study). 

In this workflow, we'll meet the p-value, but hopefully you'll see that it's just one of the statistics in the overall analysis. We'll take a data-centric approach, and  focus on data summaries (e.g. means), estimates of treatment effects (mean differences), and estimates of effect differences (differences of differences), as appropriate. 

We'll introduce the workflow using a simple dataset: the seed orchard data. This way we can focus our attention on the process. 

We organise our analyses in R as follows:
(0) Data set format: can data be imported into R?
(1) Preparation: import libraries that we'll need for the analyses.
(2) Set-up: import the data set, and do some initial checks.
(3) Data management:  set data types/ restructure/subset data as needed.
(4) Data exploration: visualisation for assessing patterns/associations.
(5) Fit statistical model:

    (a) assess model assumptions
    (b) statistical inference
    (c) obtain estimates of treatment effects (plus/minus uncertainty)
    
(6) Graphical or tabular summary of statistical model.

## Analysis workflow in R

### (1) Preparation: import libraries

It's good practice to keep the list of packages used at the top of the script, so that anyone reviewing the code can see the packages that were used.

```{r libraries, message=FALSE}
library(tidyverse)
library(equatiomatic)
library(emmeans)
library(ggbeeswarm)
library(ggResidpanel)
```

### (2) Set-up: import data

Most of the data sets we'll use are in .csv format. It's possible to import data in other file types, such as .xlsx, or formats used by SPSS, SAS or Stata. 

You'll need to provide the full path name of the file, so that read_csv can find the data file. If your .R file is in the main directory, and the data are stored in the Data/ directory, then the path name is "Data/seed orchard data.csv". 

```{r import}
seed <- read_csv()
glimpse(seed)
```

The function glimpse() shows us the data structure. We see that there are 16 observations and 3 variables. The variable names are plot, seedlot and dbh (diameter at breast height). 

### (3) Data management

Seedlot has data type character or text. In the code below, we make seedlot a factor or categorical variable. 

```{r data_management}
seed$seedlot <- 
```

### (4) Data exploration

Data exploration is arguably the most important step of the workflow. In data exploration, we can visually assess how experimental factors influence the response, how experimental factors influence the effect of other factors. We can visually assess how the response varies by plot, by day, by tray etc. 

For these data, there is only a single experimental factor: seedlot. There are a number of different ways to visualise the distribution of tree diameters (dbh) by seedlot.

#### boxplot

If distributions are unimodal with lots of data points, boxplots can be an excellent way to summarise distributions. The box outline represents the **25 -75 quartiles** of the distribution. The centre line is the data **median**, and the "whiskers" reach to the min/max data points, up to 1.5 times the box width. Data outside these these boundaries are displayed as "outliers".
```{r boxplot, fig.height=2, fig.width = 3, fig.align = 'center'}
ggplot

```

With only 8 data points in each group, it may be more visually informative to just show the actual data. We do this in ggplot by changing the geom to geom_point().

#### simple point plot

```{r points, fig.height=2, fig.width = 3, fig.align = 'center'}
ggplot
```

You may notice that there appear to be only 7 points in the P group. Two of the points have the same value, and show up as a single point. This can be misleading. One way around this problem is to "jitter" the points. You can control the amount of jitter using height= and width = parameters. For larger data sets, beeswarm plots can look less chaotic.

#### jittered point plots

```{r jitter, fig.height=2, fig.width = 3, fig.align = 'center'}
ggplot
```

#### "beeswarm" plots
```{r beeswarm, fig.height=2, fig.width = 3, fig.align = 'center'}
ggplot
```

### (5) Fitting a statistical model

Fitting a statistical model to data takes only a single line of code. The work comes in checking whether the model is a reasonable representation of the data, and summarising the key findings from the model. 

Notice the syntax of the linear model function (lm): the formula `response ~ factor` is the model specification; with response variable first, then ~, followed by factors specified by the model. The data statement indicates the source of the variables.

#### fit the model, and create model object "model.seed"

```{r model}
model.seed <- lm()

```

Statistical inference: We want to know whether the seedlot type (seed orchard of plantation) yields different tree diameters, on average. The exploratory plots suggest that seeds from the seed orchard may result in larger trees, but how strong is this evidence? Statistical inference is a principled way of addressing this question. Analysis of variance (ANOVA) compares the group mean differences to the within-group variation. 

Large between-group differences relative to within group variation (**signal:noise ratio** high) indicates evidence of treatment effect. 

Small between-group differences relative to within group variation (**signal:noise ratio** low) indicates **lack of evidence** of treatment effect.

When there is evidence that seedlot affects tree diameter, then we report mean estimates by group, treatment effect estimates (mean difference) plus/minus uncertainty (SE).

When there is a lack of evidence that seedlot affects tree diameter, we can still report mean estimates (and SE) by group, but the overall mean tree diameter is the main summary measure from this experiment. 

#### ANOVA table for "model.seed"
```{r anova}
anova(model.seed)
```

The model summarises the data as **group mean estimates** and **variation around the means**. We want to look at both of these summaries to assess whether our model is a reasonable summary of our data. Our assumptions are that the variation around the means is approximately normally distributed, the within-group variation is similar for each group, and there are no points that unduly influence the inference. 

#### Group mean estimates and treatment effect estimates
```{r group_summary}
emmeans(model.seed, pairwise~seedlot)
```

#### distribution of variation around means
```{r variation}
resid_panel(model.seed)
```

The first plot Residuals vs Fitted (top left) has *fitted values* on the x-axis and *residuals* on the y-axis. The *fitted values* are the mean values for each group (28.7 and 30.6), and the *residuals* are the observed value - fitted value. 

The second plot Normal Q-Q (top right) matches up the distribution of the "residuals" with the theoretical normal distribution. The x-axis are the theoretical quantiles of a normal distribution. The y-axis are the residuals (observed - fitted) in order from smallest to largest. The blue line shows where the points would sit if the distribution of the residuals matched a normal distribution.

The third plot Index Plot (bottom left) can be a useful plot for assessing the ordered patterns in the residuals.

The final plot (bottom right) is a histogram of the residuals, overlaid with a normal distribution.   


#### (6) Summarise model in a table or graphic

We'll spend more time on this section in future sessions. In the graphic below, we'll show group mean estimates, SE and the p-value, our measure of evidence of a difference between groups.

```{r model_summary, fig.height = 3, fig.width = 3, fig.align = 'center'}
results1<-emmeans(model.seed, ~seedlot) %>%
           as_tibble()

final_graph<-
```

You can also add the p-value to the final plot

````{r add_p_value}
testpval <- emmeans(model.seed, pairwise~seedlot)$contrast %>%
            as_tibble() %>%
            pull(p.value) %>%
            round(digits = 3)


final_graph + 
  annotate("segment", x = 1, y=33, xend = 2, yend=33)+
  annotate("text", x=1.5, y=34, size = 5,label = paste("p =", testpval))
```
