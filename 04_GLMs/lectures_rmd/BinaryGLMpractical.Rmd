---
title: "Binary GLMs"
author: "Timothee Bonnet"
date: "23 September 2022"
output: 
  html_document:
    theme: united
    highlight: pygments
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Today we will need the following packages:
```{r, message=FALSE}
library(tidyverse) #including ggplot2
library(ggbeeswarm)
library(ggResidpanel)

library(glmmTMB)
library(DHARMa)
library(emmeans)
library(car)
```


Reminder: we simulated those data, using a generative model corresponding to a binomial GLM:
```{r}
set.seed(935)
number_observations <- 30
intercept <- 1
effect <- 2

predictor <- rnorm(n = number_observations,mean = 0,sd = 1)

latent <- intercept + effect*predictor
probability <- plogis(latent)
response <- sapply(probability, FUN=function(x){rbinom(1,1,x)})

data_binary <- tibble(predictor=predictor, response=response)
ggplot(data_binary, aes(x=predictor, y=response))+ geom_beeswarm(groupOnX = FALSE)
```

A linear model (in red) shows many pathologies, whereas a binomial GLM does what we want:
```{r}
ggplot(data_binary, aes(x=predictor, y=response))+ geom_beeswarm(groupOnX = FALSE) +
  geom_smooth(method="lm", col="red", fill="red", fullrange=TRUE) + 
  geom_smooth(method="glm", col="blue", fill= "blue", method.args = list(family="binomial"), fullrange=TRUE)  +
  xlim(c(-4, 4))
```


## Practice with snow voles survival, understanding link functions and interpreting parameter estimates


The data set "voles_early.csv" contains records from the beginning of the survey of a wild rodent population. Among the variables is "survival", a binary variable indicating whether an individual captured on a given year survived to the next year. We want to understand variation in survival and in particular whether there is natural selection on body mass through survival. Other variables than body mass probably structure the variation in survival, making less clear what model we should use. Therefore we start building our models trying to see if sex, age and other variables matter for survival.

![cute snow vole](cutevole.jpg)


```{r}
survdat_early <- read_csv("Data/voles_early.csv")

summary(survdat_early)

survdat_early %>% group_by(sex) %>%
  summarize(p_survival=mean(survival), count_survival=sum(survival), count_death=sum(1-survival))

vole_s_glm <- glm(survival ~ sex, data = survdat_early, family = "binomial")
summary(vole_s_glm)

```


How to interpret the summary output? What are these parameters and how do they relate  to the probability of year-to-year survival in females and males?

```{r}
coef(vole_s_glm)

survdat_early %>% group_by(sex ) %>% summarize(mean=mean(survival)) 
```

Parameter estimates actually predict mean sex-specific survival, but it is not obvious because the GLM is fitted, not on the scale of probabilities, but on a transformed linear scale (on which effects are linear, like in a linear model).

All GLMs have such a transformation. It is called the "*Link function*".

To go from a probability to the linear scale our GLM applied a logit link function:

$$
\mathrm{logit}(p) = \log(\frac{p}{1-p})
$$

To go from model predictions on the linear scale to the probability scale we apply the inverse link function, which is
$$
\mathrm{logit}^{-1}(y) = \frac{1}{1+e^{-y}}
$$
in R you can run this inverse logit function with `plogis()`.

So, our model told us that the predicted survival for females (the intercept) was:
```{r}
1/(1+exp(-coef(vole_s_glm)[1]))
plogis(coef(vole_s_glm)[1])
```

And the predicted survival for males was:
```{r}
plogis(coef(vole_s_glm)[1] + coef(vole_s_glm)[2] )

```

In a binomial GLM, when you want to calculate something on the probability scale (that makes more sense to the human brain) from parameter estimates you:

1. Calculate the prediction using parameter estimates on the linear scale
2. Apply the inverse transformation used in the GLM. 

It does not work if you apply the inverse transformation on different parameters separately. 


#### Using `emmeans()`

It is a good idea to know how to back-transform link functions by hand: it forces you to understand how GLMs work, it is useful to simulate data and sometimes you really need to do calculations by hand. However, most of the time functions like `emmeans()`  are a useful shortcut. You need to be control the argument `type = ` (what scale do you want the prediction on? "link" means the scale of the linear model; "response" means scale of probability).

```{r}
emmeans(vole_s_glm, ~sex, type="response")
```

## What about data generation?

So, a GLM predicts probabilities, values between 0 and 1. But we observe only 0s and 1s. Does the GLM knows about that? Yes it does! The GLM relates probabilities to data in a very obvious way: for a predicted probability $p$, the GLM thinks you should observe a proportion $p$ of 1s and a proportion $1-p$ of 0s.
If it seems trivial, it is because it is. GLMs for binary data are really easy.

Other GLMs use more complex processes, so let us look more formally at how a binary GLM sees the world.

The distribution turning a probability $p$ into 0s and 1s is the bernoulli distribution, a special case of the binomial distribution. We can draw random samples from the bernoulli distribution with `rbinom(n=, size=1, prob=)`

```{r}
(bernoulli_sample <- rbinom(n = 1000, size = 1, prob = 0.3))

mean(bernoulli_sample)
```

All GLMs use distributions that have some kind of relationship between their mean and their variance. For the bernoulli, the relationship is $variance = mean*(1-mean)$, and the mean is expected to be equal to the probability.


```{r}
var(bernoulli_sample)

mean(bernoulli_sample)*(1-mean(bernoulli_sample))
```

That means that binary data are most variable for a probability of 0.5, and least variable for probabilities close to 0 or close to 1.

```{r}
nb_rows <- 1000
variability_bernoulli <- tibble(lm_value= seq(-5,5, length.out = nb_rows),
       probability = plogis(lm_value),
       observation = rbinom(n = nb_rows, size = 1, prob = probability))

ggplot(variability_bernoulli, aes(x=lm_value, y=probability, col=probability)) +
  geom_line()+
  geom_point(inherit.aes = FALSE, aes(x=lm_value, y=observation))
```

Let's simulate survival for each sex based on the predicted survival probabilities:
```{r}
pred_survival <- summary(emmeans(vole_s_glm, ~sex, type = "response"))

simulated_survival <- pred_survival %>%  
  group_by(sex) %>%
  select(prob) %>%
  summarise(survival = rbinom(n = 100, size = 1, prob = prob), prob=prob)


simulated_survival %>% group_by(sex) %>%
  summarise(simulated_mean = mean(survival), expected_mean=mean(prob),
            simulated_var = var(survival), expected_var=mean(prob)*(1-mean(prob)))

```


## What a GLM is

From previous examples we saw what a GLM is:

1. A linear model (response = intercept + slope × predictor . . . ), what you see with summary(glm1)
2. A "Link function" = a map between the linear function (−∞ to +∞) and a
probability distribution (from 0 to 1 for bernoulli)
3. A probability distribution (bernoulli, Binomial, Poisson. . . ) assumed to generate
the data (either 0 or 1 for bernoulli)

![glm scales](scales.png)


$$
y_i = \alpha + \beta x_i \\
p_i = \mathrm{logit}^{-1}(y_i) \\
\mathrm{obs}_i \sim Bernoulli(p_i)
$$



## More practice with snow voles

Let's consider the relationship between mass and survival.

```{r}

ggplot(survdat_early, aes(x = mass, y=survival)) +
  geom_point(alpha=0.2)
```

Difficult to see much on this plot. Better to add some jitter/beeswarm and a glm fit:


```{r}
ggplot(survdat_early, aes(x = mass, y=survival)) +
  geom_beeswarm(groupOnX = FALSE) +
  geom_smooth(method = "glm", method.args=list(family="binomial"))

```

```{r}
vole_glm <- glm(survival ~ mass, data = survdat_early)
summary(vole_glm)
```

So it looks like higher body mass corresponds to lower survival across the population.



```{r}
plot(simulateResiduals(vole_glm))
testResiduals(vole_glm)
DHARMa::testQuantiles(simulateResiduals(vole_glm, n = 10000))
```


However, we should realize that the negative relationship is a consequence of sex-age structure:

```{r}
ggplot(survdat_early, aes(x = mass, y=survival)) +
  geom_beeswarm(groupOnX = FALSE, aes(col=interaction(sex, age))) + 
  geom_smooth(method = "glm", method.args=list(family="binomial"))
```

We need sex and age in our models if we want to estimate the effect of mass independent of sex and age, which have rather trivial effects on survival (these animals have short life spans; adults senesce quickly and tend to get sick before their second winter; we do not think this has much to do with body mass; also, males get into nasty fights, especially when they become adults and can die from injuries.)

Let's ask ggplot to show us the effect of mass, sex and age together:
```{r}
ggplot(survdat_early, aes(x=mass, y= survival, color=interaction(sex,age)))+
  geom_beeswarm(groupOnX = FALSE) + 
  geom_smooth(method = "glm", method.args=list(family="binomial"))
```

That plot corresponds to the model:
```{r}
summary(m_vole_interaction <- glm(survival ~ 1 + mass * sex*age,
                 data=survdat_early, family = "binomial"))

car::Anova(m_vole_interaction, type="III")
```

That may be an interesting model, but it is not really what we are after. We were trying to ask *What is the effect of mass on survival*, as a way to quantify natural selection overall, not within sex-age classes.

So, a better model is:
```{r}
summary(final_model <- glm(survival ~ 1 + mass + sex*age,
                 data=survdat_early, family = "binomial"))

car::Anova(final_model, type="III")
```

```{r}
plot(simulateResiduals(final_model))
testResiduals(final_model)
DHARMa::testQuantiles(simulateResiduals(final_model, n = 10000))
```


From that model we conclude that mass is positively selected in this vole population.

Let's visualize the prediction from that model for each age-sex class:

```{r}
fullpredictions <- as_tibble(emmeans(final_model, ~age*sex + mass,
                         at = list(mass = seq(min(survdat_early$mass, na.rm = TRUE),
                                              max(survdat_early$mass, na.rm = TRUE),
                                              length.out = 100)), type="response"))

ggplot(survdat_early, aes(x=mass, y= survival, color=interaction(sex,age)))+
  geom_beeswarm(groupOnX = FALSE)+
  geom_line(data = fullpredictions, aes(x=mass, y=prob))

```

We can add confidence intervals:

```{r}
ggplot(survdat_early, aes(x=mass, y= survival, color=interaction(sex,age)))+
  geom_beeswarm(groupOnX = FALSE)+
  geom_line(data = fullpredictions, aes(x=mass, y=prob))+
  geom_ribbon(data = fullpredictions, inherit.aes = FALSE, alpha=0.1,
              aes(x=mass, ymin=asymp.LCL, ymax=asymp.UCL, fill=interaction(sex,age)))
```


Note that the juvenile and adult mass are almost non-overlapping distributions. So the predictions are extrapolating into regions where there are no voles in the data. This may be problematic. Do you think that if we could fatten juvenile females up to 60 grams their survival probability would be 75% ? 

We should probably show predictions only in the range where data exist:

```{r}
massextr <- survdat_early %>% 
  group_by(sex, age) %>%
  summarise(minmass = min(mass, na.rm = TRUE), maxmass=max(mass, na.rm = TRUE))


filteredpredictions <- fullpredictions %>% 
        filter((sex=="Female" & age=="A" & mass >= massextr$minmass[1] & mass <=massextr$maxmass[1]) |
              (sex=="Female" & age=="J" & mass >= massextr$minmass[2] & mass <=massextr$maxmass[2]) |
              (sex=="Male" & age=="A" & mass >= massextr$minmass[3] & mass <=massextr$maxmass[3]) |
              (sex=="Male" & age=="J" & mass >= massextr$minmass[4] & mass <=massextr$maxmass[4]))

ggplot(survdat_early, aes(x=mass, y= survival, color=interaction(sex,age)))+
  geom_beeswarm(groupOnX = FALSE) +
  geom_line(data=filteredpredictions, aes(y = prob)) +
  geom_ribbon(data=filteredpredictions, aes(x=mass, ymin=asymp.LCL, ymax=asymp.UCL, fill=interaction(sex,age)),
  inherit.aes = FALSE, alpha=0.3)

```

