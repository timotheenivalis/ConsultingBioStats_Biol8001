---
title: "Count Data GLM part 2"
author: "Timothee Bonnet"
date: "28 September 2021"
output: 
  html_document:
    theme: united
    highlight: pygments
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

Â¨Today:

* Understand the mean-variance relationship in count data GLMs
* Fit, evaluate and compare different models for count data

```{r, message=FALSE}
library(tidyverse)
library(ggbeeswarm)
library(janitor)
library(emmeans)
library(glmmTMB)
library(car)
library(DHARMa)
```

```{r}
gambusia <- read_csv("Data/Gambusia.csv")
```

Last time, we fitted the model:

```{r}
summary(m_poisson <- glmmTMB(No.Cop_Success ~ 1 + Treatment,
                             data=gambusia, family = poisson))
```

Using simulations, we saw that this model was not a very good representation of that data. The model is not aware of all the variation in the data:

```{r}
plot(simulateResiduals(m_poisson))
testDispersion(m_poisson)
```

```{r}
tibbsimul2 <- simulate(m_poisson, 250)%>%
  apply(1,tabyl) %>%    
  map_dfr(as_tibble) %>%
  rename(count = "newX[, i]")

ggplot(gambusia, aes(x=No.Cop_Success))+geom_bar() +
  geom_jitter(data = tibbsimul2, 
             mapping = aes(x=simul, y=n, col=as.factor(simul)), alpha=0.4)
```


## What is a count data GLM


```{r}
library(DiagrammeR)

grViz("
digraph boxes_and_circles {
node [shape = square, color = DeepSkyBlue]
response; predictor

node [shape = diamond, color=ForestGreen]
intercept; effect

node [shape = circle, color = black]
'expected value';

'expected value' -> 'average count' [ label = '  exponential']; 
'average count' -> response [ label = '  rpois(lambda=average count)', style=dashed]; 
intercept -> 'expected value';
predictor -> effect  [arrowhead = none, label = ' \U00D7']; 
effect -> 'expected value' ;
}")
```

With a simple Poisson family, a single parameter links the average count to the response. That can be a problem because the average count control both the mean, the variance, and all aspects of the distribution of the response.

### The Poisson process

Our GLM assumes that the data are generated by a Poisson process. Let's simulate that process to understand it.

```{r}
dat <- tibble(x=rpois(n = 10000, lambda = 2.8))
ggplot(dat, aes(x=x))+ geom_bar()
mean(dat$x)
var(dat$x)
```

The Poisson distribution takes a single parameter, lambda ($\lambda$). That parameter controls exactly the shape of the distribution, and is equal to the expected mean and the expected variance both. 
That is a key issue. In a Poisson distribution, the expected mean predicts the variance. There is not room for any more variation. 

In biology, this lambda is unlikely to be constant. A Poisson GLM "thinks" the predictors in the model capture all the variation in lambda, which corresponds to this set of equations:

$$
\mathrm{obs} \sim Poisson(\lambda) \\
\lambda = \mathrm{exp}(y)\\
y = \alpha + \beta x
$$

That is often not sufficient. The data would probably be better represented by 

$$
\mathrm{obs} \sim Poisson(\lambda) \\
\lambda = \mathrm{exp}(y)\\
y = \alpha + \beta x + noise
$$
That is, there is unexplained variation after accounting for the model predictors.
A Poisson GLM cannot see the noise, which produces over-dispersion, and measure uncertainty using only the variation it can see. Therefore, a Poisson GLM often under-estimate uncertainty.

If you forget about the problem of over-dispersion you will find too many false positive results. For instance, with a variance about 3 times larger than the mean, we find significant results 30% of the time when there is no true effect (ideally we expect 5%).

```{r, message=FALSE, warning=FALSE}
## Simulate data without any effect of x
pvalues <- vector(length=100)
for (i in 1:100)
{
  x <- rnorm(50)
  y <- rnorm(50)
  lambda <- exp(y)
  obs <- sapply(lambda, rpois, n=1)
  
  m0 <- glmmTMB(obs ~ x, family = "poisson")
  pvalues[i] <- summary(m0)$coefficients$cond["x", "Pr(>|z|)"]
}

mean(pvalues < 0.05)

```



### How to solve the issue of over-dispersion?

Basically, we need to give some freedom to the mean-variance relationship. There are many ways of doing that; some will work better or worse for particular datasets. There is no silver bullet. You need to try and assess how good the model is.

A first version, called "nbinom1" ("Negative-Binomial 1"), is an extension of the Poisson model in which the variance follows the equation 
$ V= m (1+\phi)$ where $\phi$ is the over-dispersion.

```{r}
summary(m_nbinom1 <- glmmTMB(No.Cop_Success ~ 1 + Treatment,
                             data=gambusia, family = nbinom1))
```

Let's evaluate this model using DHARMa and then looking at simulated distributions:
```{r}
testResiduals(m_poisson) # previous evaluation
 
testResiduals(m_nbinom1) #much better
```


```{r}
fsimul <- function(x) {
  tibble(simul=simulate(m_poisson)) %>% 
  tabyl(simul)
  }

tibbsimul2 <- map_dfr(.x = 1:100, .f = fsimul)

ggplot(gambusia, aes(x=No.Cop_Success))+geom_bar() +
  geom_jitter(data = tibbsimul2, 
             mapping = aes(x=simul, y=n, col=as.factor(simul)),
             alpha=0.4, inherit.aes = FALSE) + ggtitle("Poisson GLM")

```

```{r}
fsimul <- function(x) {
  tibble(simul=simulate(m_poisson_2)) %>% 
  tabyl(simul)
  }

tibbsimul2 <- map_dfr(.x = 1:100, .f = fsimul)

ggplot(gambusia, aes(x=No.Cop_Success))+geom_bar() +
  geom_jitter(data = tibbsimul2, 
             mapping = aes(x=simul, y=n, col=as.factor(simul)),
             alpha=0.4, inherit.aes = FALSE) + xlim(-1,12)+ ggtitle("Nbinom1 GLM")

```

In this case the "Negative Binomial 1" seems appropriate, and much better than the strict Poisson family.

**In general avoid the Poisson family.**

(unless you model over-dispersion within the Poisson family, using random effects or a secondary dispersion linear predictor; we will not cover this topic in the course. Just remember it is dangerous but not necessarily wrong if you know what you are doing!)

### Other types of count data GLMs

#### Families

In glmmTMB there are 5 basic GLM families for count data:

```{r, cache=TRUE}
summary(m_poisson <- glmmTMB(No.Cop_Success ~ 1 + Treatment, data=gambusia, family = poisson))
summary(m_genpoi <- glmmTMB(No.Cop_Success ~ 1 + Treatment, data=gambusia, family = genpois)) 
summary(m_compois <- glmmTMB(No.Cop_Success ~ 1 + Treatment, data=gambusia, family = compois))## Slow!
summary(m_nbinom1 <- glmmTMB(No.Cop_Success ~ 1 + Treatment, data=gambusia, family = nbinom1))
summary(m_nbinom2 <- glmmTMB(No.Cop_Success ~ 1 + Treatment, data=gambusia, family = nbinom2))

```

All of them return (almost exactly) the same parameter estimates: intercept = 0.52 and TreatmentWinner=0.16. However, they return different Standard Errors, z values and p values (the ` poisson` family being very different from the other ones), because they have different ideas about how variation in the data works and therefore about how sure we should be about what patterns we see.

Each family may be more or less appropriate for different response variables. It really depends on how variation relates to the response expected mean value. Sometimes, not a single one of these families will provide a good description of variation. In those cases adding random effect, or using a family with zero-inflation or a linear predictor for dispersion can be necessary (not covered in this course).

#### Predictors

Sometimes a count data GLM does not fit well and shows signs of under/over-dispersion because important predictors are missing in the model.

For instance, let's simulate data where a count data "obs" is a function of size and size on the log-scale:
```{r}
set.seed(351188)
fakedata <- tibble(size=rnorm(1000), 
                   sex=sample(c(1,2), size=1000, replace = TRUE, prob = c(0.2, 0.8)), 
                   y=1 + 0.5*size + 1.6*sex + rnorm(n = 1000, 0, 0.02),
                   obs=rpois(n = 1000, lambda = exp(y)))

```

We model obs as a function of size only:
```{r}
summary(fake_nbinom1 <- glmmTMB(obs ~ 1 + size, data=fakedata, family = nbinom1)) 
testResiduals(fake_nbinom1)
```

Here we have a case of **under-dispersion**. The model does not fit the data well and over-estimates the amount of noise in the data. In the presence of under-dispersion we expect to find fewer false positives than normal, but also more false negative; that is, our statistical model has less power to detect effects than it should.

Sometimes you can still get an okay model by fitting a different GLM, but adding the missing predictor in the model solves the issue much better:
```{r}
summary(fake_nbinom1_sex <- glmmTMB(obs ~ 1 + size + sex, data=fakedata, family = nbinom1)) 
testResiduals(fake_nbinom1_sex)
```

With the same data, if we fit sex only but not size, we get **over-dispersion**:
```{r}
summary(fake_nbinom1_sex_only <- glmmTMB(obs ~ 1 + sex, data=fakedata, family = nbinom1)) 
testResiduals(fake_nbinom1_sex_only)
```

The issue disappears when we include size in the model:
```{r}
summary(fake_nbinom1_sex <- glmmTMB(obs ~ 1 + size + sex, data=fakedata, family = nbinom1)) 
testResiduals(fake_nbinom1_sex)
```

